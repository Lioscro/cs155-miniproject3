{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from src import models, preprocessing, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters\n",
    "KEY = 'word2vec_lstm'\n",
    "DIR = os.path.join(utils.MODELS_DIR, KEY)\n",
    "\n",
    "# Word2Vec parameters\n",
    "size = 50      # dimensions of embedding space\n",
    "window = 5     # number of words for Word2Vec\n",
    "sg = 1         # whether to use skip-gram model (0: CBOW)\n",
    "iter = 100     # number of epochs\n",
    "\n",
    "# LSTM parameters\n",
    "units = 1024\n",
    "window_size = 11  # number of words for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = utils.load_shakespeare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Since we are training a character-based LSTM, we just need to map each character to a dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Joseph\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "encoding, encoded_sonnets = preprocessing.encode_words_word2vec(\n",
    "    sonnets, size=size, window=window, sg=sg, iter=iter, workers=8\n",
    ")\n",
    "n_words = len(encoding.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data.\n",
    "X = []\n",
    "Y = []\n",
    "for sonnet in encoded_sonnets:\n",
    "    x = np.zeros((len(sonnet) - window_size, window_size, size))\n",
    "    y = np.zeros((len(sonnet) - window_size, size))\n",
    "    \n",
    "    for i in range(len(sonnet) - window_size):\n",
    "        x[i] = sonnet[i:i+window_size]\n",
    "        y[i] = sonnet[i+window_size]\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "X = np.vstack(X)\n",
    "Y = np.vstack(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters.\n",
    "params = {\n",
    "    'units': units,\n",
    "    'size': size,\n",
    "    'sg': sg,\n",
    "    'iter': iter,\n",
    "    'window': window,\n",
    "    'window_size': window_size,\n",
    "    'encoding': encoding\n",
    "}\n",
    "utils.save_pickle(params, os.path.join(DIR, 'params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.WordLSTM(units, window_size, size)\n",
    "model.compile(loss='cosine_similarity', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "20846/20846 [==============================] - 7s 323us/step - loss: -0.1097\n",
      "\n",
      "Epoch 00001: loss improved from inf to -0.10973, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-001--0.1097.h5\n",
      "Epoch 2/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.1164\n",
      "\n",
      "Epoch 00002: loss improved from -0.10973 to -0.11638, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-002--0.1164.h5\n",
      "Epoch 3/1000\n",
      "20846/20846 [==============================] - 6s 302us/step - loss: -0.1265\n",
      "\n",
      "Epoch 00003: loss improved from -0.11638 to -0.12650, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-003--0.1265.h5\n",
      "Epoch 4/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.1287\n",
      "\n",
      "Epoch 00004: loss improved from -0.12650 to -0.12872, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-004--0.1287.h5\n",
      "Epoch 5/1000\n",
      "20846/20846 [==============================] - 6s 295us/step - loss: -0.1305\n",
      "\n",
      "Epoch 00005: loss improved from -0.12872 to -0.13049, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-005--0.1305.h5\n",
      "Epoch 6/1000\n",
      "20846/20846 [==============================] - 6s 290us/step - loss: -0.1320\n",
      "\n",
      "Epoch 00006: loss improved from -0.13049 to -0.13199, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-006--0.1320.h5\n",
      "Epoch 7/1000\n",
      "20846/20846 [==============================] - 7s 322us/step - loss: -0.1335\n",
      "\n",
      "Epoch 00007: loss improved from -0.13199 to -0.13345, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-007--0.1335.h5\n",
      "Epoch 8/1000\n",
      "20846/20846 [==============================] - 7s 325us/step - loss: -0.1353\n",
      "\n",
      "Epoch 00008: loss improved from -0.13345 to -0.13534, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-008--0.1353.h5\n",
      "Epoch 9/1000\n",
      "20846/20846 [==============================] - 6s 301us/step - loss: -0.13710s - l\n",
      "\n",
      "Epoch 00009: loss improved from -0.13534 to -0.13708, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-009--0.1371.h5\n",
      "Epoch 10/1000\n",
      "20846/20846 [==============================] - 6s 299us/step - loss: -0.1393\n",
      "\n",
      "Epoch 00010: loss improved from -0.13708 to -0.13934, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-010--0.1393.h5\n",
      "Epoch 11/1000\n",
      "20846/20846 [==============================] - 6s 304us/step - loss: -0.1416\n",
      "\n",
      "Epoch 00011: loss improved from -0.13934 to -0.14159, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-011--0.1416.h5\n",
      "Epoch 12/1000\n",
      "20846/20846 [==============================] - 6s 309us/step - loss: -0.1444\n",
      "\n",
      "Epoch 00012: loss improved from -0.14159 to -0.14441, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-012--0.1444.h5\n",
      "Epoch 13/1000\n",
      "20846/20846 [==============================] - 6s 304us/step - loss: -0.1485\n",
      "\n",
      "Epoch 00013: loss improved from -0.14441 to -0.14852, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-013--0.1485.h5\n",
      "Epoch 14/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.1534\n",
      "\n",
      "Epoch 00014: loss improved from -0.14852 to -0.15337, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-014--0.1534.h5\n",
      "Epoch 15/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.1598\n",
      "\n",
      "Epoch 00015: loss improved from -0.15337 to -0.15981, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-015--0.1598.h5\n",
      "Epoch 16/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.1683\n",
      "\n",
      "Epoch 00016: loss improved from -0.15981 to -0.16826, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-016--0.1683.h5\n",
      "Epoch 17/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.1787\n",
      "\n",
      "Epoch 00017: loss improved from -0.16826 to -0.17865, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-017--0.1787.h5\n",
      "Epoch 18/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.1899\n",
      "\n",
      "Epoch 00018: loss improved from -0.17865 to -0.18992, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-018--0.1899.h5\n",
      "Epoch 19/1000\n",
      "20846/20846 [==============================] - 6s 295us/step - loss: -0.2019\n",
      "\n",
      "Epoch 00019: loss improved from -0.18992 to -0.20187, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-019--0.2019.h5\n",
      "Epoch 20/1000\n",
      "20846/20846 [==============================] - 6s 306us/step - loss: -0.2138\n",
      "\n",
      "Epoch 00020: loss improved from -0.20187 to -0.21381, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-020--0.2138.h5\n",
      "Epoch 21/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2249\n",
      "\n",
      "Epoch 00021: loss improved from -0.21381 to -0.22493, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-021--0.2249.h5\n",
      "Epoch 22/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2356\n",
      "\n",
      "Epoch 00022: loss improved from -0.22493 to -0.23556, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-022--0.2356.h5\n",
      "Epoch 23/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.2449\n",
      "\n",
      "Epoch 00023: loss improved from -0.23556 to -0.24493, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-023--0.2449.h5\n",
      "Epoch 24/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.2516\n",
      "\n",
      "Epoch 00024: loss improved from -0.24493 to -0.25161, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-024--0.2516.h5\n",
      "Epoch 25/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2590\n",
      "\n",
      "Epoch 00025: loss improved from -0.25161 to -0.25896, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-025--0.2590.h5\n",
      "Epoch 26/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2637\n",
      "\n",
      "Epoch 00026: loss improved from -0.25896 to -0.26374, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-026--0.2637.h5\n",
      "Epoch 27/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.2689\n",
      "\n",
      "Epoch 00027: loss improved from -0.26374 to -0.26894, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-027--0.2689.h5\n",
      "Epoch 28/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.2729\n",
      "\n",
      "Epoch 00028: loss improved from -0.26894 to -0.27289, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-028--0.2729.h5\n",
      "Epoch 29/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.2761\n",
      "\n",
      "Epoch 00029: loss improved from -0.27289 to -0.27609, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-029--0.2761.h5\n",
      "Epoch 30/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.2792\n",
      "\n",
      "Epoch 00030: loss improved from -0.27609 to -0.27923, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-030--0.2792.h5\n",
      "Epoch 31/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.2818\n",
      "\n",
      "Epoch 00031: loss improved from -0.27923 to -0.28184, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-031--0.2818.h5\n",
      "Epoch 32/1000\n",
      "20846/20846 [==============================] - 6s 306us/step - loss: -0.2845\n",
      "\n",
      "Epoch 00032: loss improved from -0.28184 to -0.28447, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-032--0.2845.h5\n",
      "Epoch 33/1000\n",
      "20846/20846 [==============================] - 7s 313us/step - loss: -0.2862\n",
      "\n",
      "Epoch 00033: loss improved from -0.28447 to -0.28620, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-033--0.2862.h5\n",
      "Epoch 34/1000\n",
      "20846/20846 [==============================] - 7s 313us/step - loss: -0.2880\n",
      "\n",
      "Epoch 00034: loss improved from -0.28620 to -0.28800, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-034--0.2880.h5\n",
      "Epoch 35/1000\n",
      "20846/20846 [==============================] - 7s 314us/step - loss: -0.2898\n",
      "\n",
      "Epoch 00035: loss improved from -0.28800 to -0.28985, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-035--0.2898.h5\n",
      "Epoch 36/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.2918\n",
      "\n",
      "Epoch 00036: loss improved from -0.28985 to -0.29179, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-036--0.2918.h5\n",
      "Epoch 37/1000\n",
      "20846/20846 [==============================] - 6s 302us/step - loss: -0.2931\n",
      "\n",
      "Epoch 00037: loss improved from -0.29179 to -0.29307, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-037--0.2931.h5\n",
      "Epoch 38/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2945\n",
      "\n",
      "Epoch 00038: loss improved from -0.29307 to -0.29453, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-038--0.2945.h5\n",
      "Epoch 39/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2959\n",
      "\n",
      "Epoch 00039: loss improved from -0.29453 to -0.29588, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-039--0.2959.h5\n",
      "Epoch 40/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.2975\n",
      "\n",
      "Epoch 00040: loss improved from -0.29588 to -0.29749, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-040--0.2975.h5\n",
      "Epoch 41/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.2994\n",
      "\n",
      "Epoch 00041: loss improved from -0.29749 to -0.29936, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-041--0.2994.h5\n",
      "Epoch 42/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.3004\n",
      "\n",
      "Epoch 00042: loss improved from -0.29936 to -0.30036, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-042--0.3004.h5\n",
      "Epoch 43/1000\n",
      "20846/20846 [==============================] - 6s 302us/step - loss: -0.3014\n",
      "\n",
      "Epoch 00043: loss improved from -0.30036 to -0.30136, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-043--0.3014.h5\n",
      "Epoch 44/1000\n",
      "20846/20846 [==============================] - 6s 303us/step - loss: -0.3028\n",
      "\n",
      "Epoch 00044: loss improved from -0.30136 to -0.30280, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-044--0.3028.h5\n",
      "Epoch 45/1000\n",
      "20846/20846 [==============================] - 6s 301us/step - loss: -0.3039\n",
      "\n",
      "Epoch 00045: loss improved from -0.30280 to -0.30387, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-045--0.3039.h5\n",
      "Epoch 46/1000\n",
      "20846/20846 [==============================] - 7s 337us/step - loss: -0.3047\n",
      "\n",
      "Epoch 00046: loss improved from -0.30387 to -0.30468, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-046--0.3047.h5\n",
      "Epoch 47/1000\n",
      "20846/20846 [==============================] - 6s 293us/step - loss: -0.3057\n",
      "\n",
      "Epoch 00047: loss improved from -0.30468 to -0.30573, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-047--0.3057.h5\n",
      "Epoch 48/1000\n",
      "20846/20846 [==============================] - 6s 290us/step - loss: -0.3070\n",
      "\n",
      "Epoch 00048: loss improved from -0.30573 to -0.30697, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-048--0.3070.h5\n",
      "Epoch 49/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3076\n",
      "\n",
      "Epoch 00049: loss improved from -0.30697 to -0.30765, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-049--0.3076.h5\n",
      "Epoch 50/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3085\n",
      "\n",
      "Epoch 00050: loss improved from -0.30765 to -0.30845, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-050--0.3085.h5\n",
      "Epoch 51/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3093\n",
      "\n",
      "Epoch 00051: loss improved from -0.30845 to -0.30926, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-051--0.3093.h5\n",
      "Epoch 52/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3102\n",
      "\n",
      "Epoch 00052: loss improved from -0.30926 to -0.31021, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-052--0.3102.h5\n",
      "Epoch 53/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3114\n",
      "\n",
      "Epoch 00053: loss improved from -0.31021 to -0.31143, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-053--0.3114.h5\n",
      "Epoch 54/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3119\n",
      "\n",
      "Epoch 00054: loss improved from -0.31143 to -0.31186, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-054--0.3119.h5\n",
      "Epoch 55/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3127\n",
      "\n",
      "Epoch 00055: loss improved from -0.31186 to -0.31269, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-055--0.3127.h5\n",
      "Epoch 56/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3133\n",
      "\n",
      "Epoch 00056: loss improved from -0.31269 to -0.31327, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-056--0.3133.h5\n",
      "Epoch 57/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3140\n",
      "\n",
      "Epoch 00057: loss improved from -0.31327 to -0.31403, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-057--0.3140.h5\n",
      "Epoch 58/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3147\n",
      "\n",
      "Epoch 00058: loss improved from -0.31403 to -0.31465, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-058--0.3147.h5\n",
      "Epoch 59/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3155\n",
      "\n",
      "Epoch 00059: loss improved from -0.31465 to -0.31549, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-059--0.3155.h5\n",
      "Epoch 60/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3163\n",
      "\n",
      "Epoch 00060: loss improved from -0.31549 to -0.31630, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-060--0.3163.h5\n",
      "Epoch 61/1000\n",
      "20846/20846 [==============================] - 6s 311us/step - loss: -0.3169\n",
      "\n",
      "Epoch 00061: loss improved from -0.31630 to -0.31689, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-061--0.3169.h5\n",
      "Epoch 62/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.3174\n",
      "\n",
      "Epoch 00062: loss improved from -0.31689 to -0.31741, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-062--0.3174.h5\n",
      "Epoch 63/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3181\n",
      "\n",
      "Epoch 00063: loss improved from -0.31741 to -0.31807, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-063--0.3181.h5\n",
      "Epoch 64/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3185\n",
      "\n",
      "Epoch 00064: loss improved from -0.31807 to -0.31849, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-064--0.3185.h5\n",
      "Epoch 65/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3191\n",
      "\n",
      "Epoch 00065: loss improved from -0.31849 to -0.31905, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-065--0.3191.h5\n",
      "Epoch 66/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.3193\n",
      "\n",
      "Epoch 00066: loss improved from -0.31905 to -0.31933, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-066--0.3193.h5\n",
      "Epoch 67/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3200\n",
      "\n",
      "Epoch 00067: loss improved from -0.31933 to -0.32003, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-067--0.3200.h5\n",
      "Epoch 68/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3205\n",
      "\n",
      "Epoch 00068: loss improved from -0.32003 to -0.32045, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-068--0.3205.h5\n",
      "Epoch 69/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3209\n",
      "\n",
      "Epoch 00069: loss improved from -0.32045 to -0.32091, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-069--0.3209.h5\n",
      "Epoch 70/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3214\n",
      "\n",
      "Epoch 00070: loss improved from -0.32091 to -0.32136, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-070--0.3214.h5\n",
      "Epoch 71/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3217\n",
      "\n",
      "Epoch 00071: loss improved from -0.32136 to -0.32173, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-071--0.3217.h5\n",
      "Epoch 72/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3220\n",
      "\n",
      "Epoch 00072: loss improved from -0.32173 to -0.32200, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-072--0.3220.h5\n",
      "Epoch 73/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3225\n",
      "\n",
      "Epoch 00073: loss improved from -0.32200 to -0.32254, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-073--0.3225.h5\n",
      "Epoch 74/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3230\n",
      "\n",
      "Epoch 00074: loss improved from -0.32254 to -0.32299, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-074--0.3230.h5\n",
      "Epoch 75/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3235\n",
      "\n",
      "Epoch 00075: loss improved from -0.32299 to -0.32350, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-075--0.3235.h5\n",
      "Epoch 76/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3237\n",
      "\n",
      "Epoch 00076: loss improved from -0.32350 to -0.32370, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-076--0.3237.h5\n",
      "Epoch 77/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3240\n",
      "\n",
      "Epoch 00077: loss improved from -0.32370 to -0.32400, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-077--0.3240.h5\n",
      "Epoch 78/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3246\n",
      "\n",
      "Epoch 00078: loss improved from -0.32400 to -0.32456, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-078--0.3246.h5\n",
      "Epoch 79/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3250\n",
      "\n",
      "Epoch 00079: loss improved from -0.32456 to -0.32503, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-079--0.3250.h5\n",
      "Epoch 80/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3253\n",
      "\n",
      "Epoch 00080: loss improved from -0.32503 to -0.32532, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-080--0.3253.h5\n",
      "Epoch 81/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3256\n",
      "\n",
      "Epoch 00081: loss improved from -0.32532 to -0.32558, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-081--0.3256.h5\n",
      "Epoch 82/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3260\n",
      "\n",
      "Epoch 00082: loss improved from -0.32558 to -0.32597, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-082--0.3260.h5\n",
      "Epoch 83/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3262\n",
      "\n",
      "Epoch 00083: loss improved from -0.32597 to -0.32622, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-083--0.3262.h5\n",
      "Epoch 84/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3265\n",
      "\n",
      "Epoch 00084: loss improved from -0.32622 to -0.32654, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-084--0.3265.h5\n",
      "Epoch 85/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3269\n",
      "\n",
      "Epoch 00085: loss improved from -0.32654 to -0.32689, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-085--0.3269.h5\n",
      "Epoch 86/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3274\n",
      "\n",
      "Epoch 00086: loss improved from -0.32689 to -0.32744, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-086--0.3274.h5\n",
      "Epoch 87/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3279\n",
      "\n",
      "Epoch 00087: loss improved from -0.32744 to -0.32789, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-087--0.3279.h5\n",
      "Epoch 88/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3279\n",
      "\n",
      "Epoch 00088: loss did not improve from -0.32789\n",
      "Epoch 89/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3283\n",
      "\n",
      "Epoch 00089: loss improved from -0.32789 to -0.32831, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-089--0.3283.h5\n",
      "Epoch 90/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3287\n",
      "\n",
      "Epoch 00090: loss improved from -0.32831 to -0.32865, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-090--0.3287.h5\n",
      "Epoch 91/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3290\n",
      "\n",
      "Epoch 00091: loss improved from -0.32865 to -0.32895, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-091--0.3290.h5\n",
      "Epoch 92/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3294\n",
      "\n",
      "Epoch 00092: loss improved from -0.32895 to -0.32941, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-092--0.3294.h5\n",
      "Epoch 93/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3295\n",
      "\n",
      "Epoch 00093: loss improved from -0.32941 to -0.32953, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-093--0.3295.h5\n",
      "Epoch 94/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3298\n",
      "\n",
      "Epoch 00094: loss improved from -0.32953 to -0.32976, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-094--0.3298.h5\n",
      "Epoch 95/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3300\n",
      "\n",
      "Epoch 00095: loss improved from -0.32976 to -0.32999, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-095--0.3300.h5\n",
      "Epoch 96/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3302\n",
      "\n",
      "Epoch 00096: loss improved from -0.32999 to -0.33023, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-096--0.3302.h5\n",
      "Epoch 97/1000\n",
      "20846/20846 [==============================] - 6s 310us/step - loss: -0.3306\n",
      "\n",
      "Epoch 00097: loss improved from -0.33023 to -0.33056, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-097--0.3306.h5\n",
      "Epoch 98/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3308\n",
      "\n",
      "Epoch 00098: loss improved from -0.33056 to -0.33080, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-098--0.3308.h5\n",
      "Epoch 99/1000\n",
      "20846/20846 [==============================] - 6s 299us/step - loss: -0.3310\n",
      "\n",
      "Epoch 00099: loss improved from -0.33080 to -0.33103, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-099--0.3310.h5\n",
      "Epoch 100/1000\n",
      "20846/20846 [==============================] - 6s 299us/step - loss: -0.3311\n",
      "\n",
      "Epoch 00100: loss improved from -0.33103 to -0.33108, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-100--0.3311.h5\n",
      "Epoch 101/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3312\n",
      "\n",
      "Epoch 00101: loss improved from -0.33108 to -0.33118, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-101--0.3312.h5\n",
      "Epoch 102/1000\n",
      "20846/20846 [==============================] - 6s 301us/step - loss: -0.3317\n",
      "\n",
      "Epoch 00102: loss improved from -0.33118 to -0.33172, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-102--0.3317.h5\n",
      "Epoch 103/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3323\n",
      "\n",
      "Epoch 00103: loss improved from -0.33172 to -0.33228, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-103--0.3323.h5\n",
      "Epoch 104/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3325\n",
      "\n",
      "Epoch 00104: loss improved from -0.33228 to -0.33253, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-104--0.3325.h5\n",
      "Epoch 105/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3329\n",
      "\n",
      "Epoch 00105: loss improved from -0.33253 to -0.33290, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-105--0.3329.h5\n",
      "Epoch 106/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3330\n",
      "\n",
      "Epoch 00106: loss improved from -0.33290 to -0.33297, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-106--0.3330.h5\n",
      "Epoch 107/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3332\n",
      "\n",
      "Epoch 00107: loss improved from -0.33297 to -0.33316, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-107--0.3332.h5\n",
      "Epoch 108/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3329\n",
      "\n",
      "Epoch 00108: loss did not improve from -0.33316\n",
      "Epoch 109/1000\n",
      "20846/20846 [==============================] - 6s 288us/step - loss: -0.3332\n",
      "\n",
      "Epoch 00109: loss improved from -0.33316 to -0.33325, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-109--0.3332.h5\n",
      "Epoch 110/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3335\n",
      "\n",
      "Epoch 00110: loss improved from -0.33325 to -0.33351, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-110--0.3335.h5\n",
      "Epoch 111/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3337\n",
      "\n",
      "Epoch 00111: loss improved from -0.33351 to -0.33370, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-111--0.3337.h5\n",
      "Epoch 112/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3340\n",
      "\n",
      "Epoch 00112: loss improved from -0.33370 to -0.33397, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-112--0.3340.h5\n",
      "Epoch 113/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3342\n",
      "\n",
      "Epoch 00113: loss improved from -0.33397 to -0.33415, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-113--0.3342.h5\n",
      "Epoch 114/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3342\n",
      "\n",
      "Epoch 00114: loss improved from -0.33415 to -0.33424, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-114--0.3342.h5\n",
      "Epoch 115/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3344\n",
      "\n",
      "Epoch 00115: loss improved from -0.33424 to -0.33440, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-115--0.3344.h5\n",
      "Epoch 116/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3345\n",
      "\n",
      "Epoch 00116: loss improved from -0.33440 to -0.33455, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-116--0.3345.h5\n",
      "Epoch 117/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3346\n",
      "\n",
      "Epoch 00117: loss improved from -0.33455 to -0.33464, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-117--0.3346.h5\n",
      "Epoch 118/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3347\n",
      "\n",
      "Epoch 00118: loss improved from -0.33464 to -0.33473, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-118--0.3347.h5\n",
      "Epoch 119/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3350\n",
      "\n",
      "Epoch 00119: loss improved from -0.33473 to -0.33496, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-119--0.3350.h5\n",
      "Epoch 120/1000\n",
      "20846/20846 [==============================] - 6s 303us/step - loss: -0.3351\n",
      "\n",
      "Epoch 00120: loss improved from -0.33496 to -0.33510, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-120--0.3351.h5\n",
      "Epoch 121/1000\n",
      "20846/20846 [==============================] - 7s 320us/step - loss: -0.3352\n",
      "\n",
      "Epoch 00121: loss improved from -0.33510 to -0.33520, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-121--0.3352.h5\n",
      "Epoch 122/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3355\n",
      "\n",
      "Epoch 00122: loss improved from -0.33520 to -0.33552, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-122--0.3355.h5\n",
      "Epoch 123/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3356\n",
      "\n",
      "Epoch 00123: loss improved from -0.33552 to -0.33561, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-123--0.3356.h5\n",
      "Epoch 124/1000\n",
      "20846/20846 [==============================] - 6s 301us/step - loss: -0.3358\n",
      "\n",
      "Epoch 00124: loss improved from -0.33561 to -0.33579, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-124--0.3358.h5\n",
      "Epoch 125/1000\n",
      "20846/20846 [==============================] - 6s 300us/step - loss: -0.3357\n",
      "\n",
      "Epoch 00125: loss did not improve from -0.33579\n",
      "Epoch 126/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3355\n",
      "\n",
      "Epoch 00126: loss did not improve from -0.33579\n",
      "Epoch 127/1000\n",
      "20846/20846 [==============================] - 6s 299us/step - loss: -0.3361\n",
      "\n",
      "Epoch 00127: loss improved from -0.33579 to -0.33609, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-127--0.3361.h5\n",
      "Epoch 128/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3364\n",
      "\n",
      "Epoch 00128: loss improved from -0.33609 to -0.33643, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-128--0.3364.h5\n",
      "Epoch 129/1000\n",
      "20846/20846 [==============================] - 6s 299us/step - loss: -0.3365\n",
      "\n",
      "Epoch 00129: loss improved from -0.33643 to -0.33652, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-129--0.3365.h5\n",
      "Epoch 130/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3365\n",
      "\n",
      "Epoch 00130: loss improved from -0.33652 to -0.33653, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-130--0.3365.h5\n",
      "Epoch 131/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3368\n",
      "\n",
      "Epoch 00131: loss improved from -0.33653 to -0.33677, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-131--0.3368.h5\n",
      "Epoch 132/1000\n",
      "20846/20846 [==============================] - 6s 303us/step - loss: -0.3369\n",
      "\n",
      "Epoch 00132: loss improved from -0.33677 to -0.33689, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-132--0.3369.h5\n",
      "Epoch 133/1000\n",
      "20846/20846 [==============================] - 6s 302us/step - loss: -0.3370\n",
      "\n",
      "Epoch 00133: loss improved from -0.33689 to -0.33699, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-133--0.3370.h5\n",
      "Epoch 134/1000\n",
      "20846/20846 [==============================] - 6s 293us/step - loss: -0.3370\n",
      "\n",
      "Epoch 00134: loss improved from -0.33699 to -0.33703, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-134--0.3370.h5\n",
      "Epoch 135/1000\n",
      "20846/20846 [==============================] - 6s 301us/step - loss: -0.3369\n",
      "\n",
      "Epoch 00135: loss did not improve from -0.33703\n",
      "Epoch 136/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3371\n",
      "\n",
      "Epoch 00136: loss improved from -0.33703 to -0.33708, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-136--0.3371.h5\n",
      "Epoch 137/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3373\n",
      "\n",
      "Epoch 00137: loss improved from -0.33708 to -0.33734, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-137--0.3373.h5\n",
      "Epoch 138/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3375\n",
      "\n",
      "Epoch 00138: loss improved from -0.33734 to -0.33746, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-138--0.3375.h5\n",
      "Epoch 139/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3375\n",
      "\n",
      "Epoch 00139: loss improved from -0.33746 to -0.33747, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-139--0.3375.h5\n",
      "Epoch 140/1000\n",
      "20846/20846 [==============================] - 6s 304us/step - loss: -0.3374\n",
      "\n",
      "Epoch 00140: loss did not improve from -0.33747\n",
      "Epoch 141/1000\n",
      "20846/20846 [==============================] - 6s 289us/step - loss: -0.3375\n",
      "\n",
      "Epoch 00141: loss improved from -0.33747 to -0.33752, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-141--0.3375.h5\n",
      "Epoch 142/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.33770s - - ETA: 0s - los\n",
      "\n",
      "Epoch 00142: loss improved from -0.33752 to -0.33774, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-142--0.3377.h5\n",
      "Epoch 143/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3379\n",
      "\n",
      "Epoch 00143: loss improved from -0.33774 to -0.33793, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-143--0.3379.h5\n",
      "Epoch 144/1000\n",
      "20846/20846 [==============================] - 6s 303us/step - loss: -0.3381\n",
      "\n",
      "Epoch 00144: loss improved from -0.33793 to -0.33813, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-144--0.3381.h5\n",
      "Epoch 145/1000\n",
      "20846/20846 [==============================] - 6s 303us/step - loss: -0.3382\n",
      "\n",
      "Epoch 00145: loss improved from -0.33813 to -0.33816, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-145--0.3382.h5\n",
      "Epoch 146/1000\n",
      "20846/20846 [==============================] - 6s 297us/step - loss: -0.3383\n",
      "\n",
      "Epoch 00146: loss improved from -0.33816 to -0.33827, saving model to C:\\Users\\Joseph\\Documents\\GitHub\\cs155-miniproject3\\models\\word2vec_lstm\\model-146--0.3383.h5\n",
      "Epoch 147/1000\n",
      "20846/20846 [==============================] - 6s 298us/step - loss: -0.3380\n",
      "\n",
      "Epoch 00147: loss did not improve from -0.33827\n",
      "Epoch 148/1000\n",
      " 8704/20846 [===========>..................] - ETA: 3s - loss: -0.3305"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-35c01525659e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Early stopping condition. Stop when loss has stopped decreasing for 10 epochs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\joseph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Save model with best accuracy.\n",
    "save_path = os.path.join(DIR, 'model-{epoch:03d}-{loss:.4f}.h5')\n",
    "checkpoint = ModelCheckpoint(save_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# Early stopping condition. Stop when loss has stopped decreasing for 10 epochs.\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)\n",
    "model.fit(X, Y, epochs=1000, batch_size=64, callbacks=[checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
